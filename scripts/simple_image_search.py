#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Google Images —á–µ—Ä–µ–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥.
"""

import sys
import os
import json
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote, urlencode
from io import BytesIO
from PIL import Image

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class SimpleImageSearch:
    """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤."""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞."""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })

    def search_google_images_alt(self, query: str, num_images: int = 5) -> list:
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google Images."""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è Google Images
            params = {
                'q': query,
                'tbm': 'isch',  # Image search
                'hl': 'en',
                'gl': 'us',
                'ijn': '0'
            }
            
            url = "https://www.google.com/search?" + urlencode(params)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            images = []
            
            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
            # –ú–µ—Ç–æ–¥ 1: data-src –∞—Ç—Ä–∏–±—É—Ç—ã
            for img in soup.find_all('img'):
                src = img.get('data-src') or img.get('src')
                if src and src.startswith('http'):
                    if not any(skip in src.lower() for skip in ['gstatic', 'google', 'googleapis']):
                        images.append(src)
                        if len(images) >= num_images:
                            break
            
            # –ú–µ—Ç–æ–¥ 2: –ò—â–µ–º –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö JSON –¥–∞–Ω–Ω—ã–µ
            if len(images) < num_images:
                for script in soup.find_all('script'):
                    if script.string and 'AF_initDataCallback' in script.string:
                        try:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞
                            start = script.string.find('[')
                            end = script.string.rfind(']') + 1
                            if start != -1 and end != 0:
                                json_text = script.string[start:end]
                                # –ò—â–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ JSON
                                import re
                                urls = re.findall(r'https?://[^"]+\.(?:jpg|jpeg|png|webp)', json_text)
                                for url in urls:
                                    if not any(skip in url.lower() for skip in ['gstatic', 'google', 'googleapis']):
                                        if url not in images:
                                            images.append(url)
                                            if len(images) >= num_images:
                                                break
                        except:
                            continue
            
            print(f"‚úÖ Google Images (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π): –Ω–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            return images[:num_images]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Google Images: {e}")
            return []

    def search_yandex_images(self, query: str, num_images: int = 5) -> list:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∏–Ω–∫–∏."""
        try:
            # URL –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∏–Ω–æ–∫
            params = {
                'text': query,
                'type': 'photo',
                'isize': 'large'
            }
            
            url = "https://yandex.ru/images/search?" + urlencode(params)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            images = []
            
            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            for item in soup.find_all('div', {'class': 'serp-item'}):
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                    data_bem = item.get('data-bem')
                    if data_bem:
                        data = json.loads(data_bem)
                        if 'serp-item' in data:
                            img_data = data['serp-item']
                            if 'img_href' in img_data:
                                images.append(img_data['img_href'])
                            elif 'preview' in img_data:
                                for preview in img_data['preview']:
                                    if 'url' in preview:
                                        images.append(preview['url'])
                                        break
                            
                            if len(images) >= num_images:
                                break
                except:
                    continue
            
            print(f"‚úÖ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∏–Ω–∫–∏: –Ω–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            return images[:num_images]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∏–Ω–∫–∞—Ö: {e}")
            return []

    def search_duckduckgo_images_improved(self, query: str, num_images: int = 5) -> list:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo."""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º DuckDuckGo API endpoint
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/json, text/javascript, */*; q=0.01',
                'X-Requested-With': 'XMLHttpRequest',
            }
            
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
            token_url = f"https://duckduckgo.com/?q={quote(query)}&iar=images&iax=images&ia=images"
            token_response = self.session.get(token_url, headers=headers, timeout=10)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º vqd —Ç–æ–∫–µ–Ω
            import re
            vqd_match = re.search(r'vqd=([\d-]+)', token_response.text)
            if not vqd_match:
                vqd_match = re.search(r'"vqd":"([\d-]+)"', token_response.text)
            
            if vqd_match:
                vqd = vqd_match.group(1)
                
                # –¢–µ–ø–µ—Ä—å –¥–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
                api_url = f"https://duckduckgo.com/i.js"
                params = {
                    'l': 'us-en',
                    'o': 'json',
                    'q': query,
                    'vqd': vqd,
                    'f': ',,,',
                    'p': '1',
                    'v7exp': 'a',
                }
                
                response = self.session.get(api_url, params=params, headers=headers, timeout=10)
                data = response.json()
                
                images = []
                if 'results' in data:
                    for result in data['results'][:num_images]:
                        if 'image' in result:
                            images.append(result['image'])
                        elif 'thumbnail' in result:
                            images.append(result['thumbnail'])
                
                print(f"‚úÖ DuckDuckGo (—É–ª—É—á—à–µ–Ω–Ω—ã–π): –Ω–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                return images
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ DuckDuckGo: {e}")
            
        return []

    def search_all_sources(self, query: str, num_images: int = 5) -> list:
        """–ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º."""
        print(f"\nüîç –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è: '{query}'")
        print("=" * 50)
        
        all_images = []
        
        # –ü—Ä–æ–±—É–µ–º Google Images (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π)
        images = self.search_google_images_alt(query, num_images)
        all_images.extend(images)
        
        # –ï—Å–ª–∏ –º–∞–ª–æ, –ø—Ä–æ–±—É–µ–º –Ø–Ω–¥–µ–∫—Å
        if len(all_images) < num_images:
            images = self.search_yandex_images(query, num_images - len(all_images))
            all_images.extend(images)
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –º–∞–ª–æ, –ø—Ä–æ–±—É–µ–º DuckDuckGo
        if len(all_images) < num_images:
            images = self.search_duckduckgo_images_improved(query, num_images - len(all_images))
            all_images.extend(images)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_images = []
        seen = set()
        for img in all_images:
            if img not in seen:
                seen.add(img)
                unique_images.append(img)
        
        print(f"\n‚úÖ –ò–¢–û–ì–û –Ω–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(unique_images)}")
        return unique_images[:num_images]

    def download_and_save_image(self, url: str, filename: str) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        try:
            print(f"üì• –ó–∞–≥—Ä—É–∂–∞—é: {url}")
            
            response = self.session.get(url, timeout=15, stream=True)
            response.raise_for_status()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
            content_length = response.headers.get('content-length')
            if content_length and int(content_length) < 1000:
                print(f"‚ö†Ô∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ: {content_length} –±–∞–π—Ç")
                return False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_data = BytesIO()
            for chunk in response.iter_content(chunk_size=8192):
                image_data.write(chunk)
            
            image_data.seek(0)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            try:
                with Image.open(image_data) as img:
                    width, height = img.size
                    if width < 100 or height < 100:
                        print(f"‚ö†Ô∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ: {width}x{height}")
                        return False
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                    image_data.seek(0)
                    filepath = f"./demo_images/{filename}"
                    
                    with open(filepath, 'wb') as f:
                        f.write(image_data.getvalue())
                    
                    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath} ({width}x{height})")
                    return True
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return False


def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ü–û–ò–°–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô")
    print("=" * 60)
    
    searcher = SimpleImageSearch()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã
    test_products = [
        "iPhone 15 Pro Max",
        "MacBook Air M3",
        "Sony WH-1000XM5"
    ]
    
    for product in test_products:
        # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        images = searcher.search_all_sources(product, 3)
        
        if images:
            print(f"\nüì∏ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è '{product}'...")
            
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—Ä–≤–æ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            for i, img_url in enumerate(images[:1]):
                safe_name = "".join(c for c in product if c.isalnum() or c in (' ', '-')).rstrip()
                safe_name = safe_name.replace(' ', '_')
                filename = f"{safe_name}_test.jpg"
                
                if searcher.download_and_save_image(img_url, filename):
                    break
                else:
                    print(f"‚ö†Ô∏è  –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
                    if i < len(images) - 1:
                        if searcher.download_and_save_image(images[i+1], filename):
                            break
        else:
            print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è '{product}'")
        
        print("-" * 60)
    
    print("\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    import os
    demo_dir = "./demo_images"
    if os.path.exists(demo_dir):
        files = os.listdir(demo_dir)
        if files:
            print("\nüìÇ –°–û–•–†–ê–ù–ï–ù–ù–´–ï –§–ê–ô–õ–´:")
            for file in files:
                if file.endswith('_test.jpg'):
                    filepath = os.path.join(demo_dir, file)
                    size = os.path.getsize(filepath)
                    print(f"   üìÑ {file} ({size:,} –±–∞–π—Ç)")


if __name__ == "__main__":
    main()
